{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5c40e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.session.SparkSession'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02186e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690c557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count\n",
    "textFile = spark.read.text(\"README.md\")\n",
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc5db2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='# Apache Spark')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frist\n",
    "textFile.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c50a6129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter\n",
    "linesWithSpark = textFile.filter(textFile.value.contains(\"Spark\"))\n",
    "textFile.filter(textFile.value.contains(\"Spark\")).count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c7c3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import *\n",
    "\n",
    "#textFile.select(size(split(textFile.value, \"\\s+\")).name(\"numWords\")).agg(max(col(\"numWords\"))).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "669f110a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='[![PySpark', count=1),\n",
       " Row(word='online', count=1),\n",
       " Row(word='graphs', count=1),\n",
       " Row(word='[\"Building', count=1),\n",
       " Row(word='documentation', count=3),\n",
       " Row(word='command,', count=2),\n",
       " Row(word='abbreviated', count=1),\n",
       " Row(word='overview', count=1),\n",
       " Row(word='rich', count=1),\n",
       " Row(word='set', count=2),\n",
       " Row(word='-DskipTests', count=1),\n",
       " Row(word='1,000,000,000:', count=2),\n",
       " Row(word='name', count=1),\n",
       " Row(word='[\"Specifying', count=1),\n",
       " Row(word='stream', count=1),\n",
       " Row(word='run:', count=1),\n",
       " Row(word='not', count=1),\n",
       " Row(word='programs', count=2),\n",
       " Row(word='tests', count=2),\n",
       " Row(word='./dev/run-tests', count=1),\n",
       " Row(word='will', count=1),\n",
       " Row(word='[run', count=1),\n",
       " Row(word='particular', count=2),\n",
       " Row(word='Alternatively,', count=1),\n",
       " Row(word='must', count=1),\n",
       " Row(word='using', count=3),\n",
       " Row(word='./build/mvn', count=1),\n",
       " Row(word='you', count=4),\n",
       " Row(word='MLlib', count=1),\n",
       " Row(word='DataFrames,', count=1),\n",
       " Row(word='variable', count=1),\n",
       " Row(word='Note', count=1),\n",
       " Row(word='core', count=1),\n",
       " Row(word='protocols', count=1),\n",
       " Row(word='Guide](https://spark.apache.org/docs/latest/configuration.html)', count=1),\n",
       " Row(word='guidance', count=2),\n",
       " Row(word='shell:', count=2),\n",
       " Row(word='can', count=6),\n",
       " Row(word='site,', count=1),\n",
       " Row(word='*', count=4),\n",
       " Row(word='systems.', count=1),\n",
       " Row(word='[building', count=1),\n",
       " Row(word='configure', count=1),\n",
       " Row(word='for', count=12),\n",
       " Row(word='README', count=1),\n",
       " Row(word='Interactive', count=2),\n",
       " Row(word='how', count=3),\n",
       " Row(word='[Configuration', count=1),\n",
       " Row(word='Hive', count=2),\n",
       " Row(word='provides', count=1),\n",
       " Row(word='Hadoop-supported', count=1),\n",
       " Row(word='pre-built', count=1),\n",
       " Row(word='[\"Useful', count=1),\n",
       " Row(word='directory.', count=1),\n",
       " Row(word='Example', count=1),\n",
       " Row(word='example', count=3),\n",
       " Row(word='Kubernetes', count=1),\n",
       " Row(word='one', count=2),\n",
       " Row(word='MASTER', count=1),\n",
       " Row(word='guide](https://spark.apache.org/contributing.html)', count=1),\n",
       " Row(word='in', count=5),\n",
       " Row(word='library', count=1),\n",
       " Row(word='Spark.', count=1),\n",
       " Row(word='contains', count=1),\n",
       " Row(word='Configuration', count=1),\n",
       " Row(word='programming', count=1),\n",
       " Row(word='with', count=3),\n",
       " Row(word='contributing', count=1),\n",
       " Row(word='downloaded', count=1),\n",
       " Row(word='1000).count()', count=2),\n",
       " Row(word='comes', count=1),\n",
       " Row(word='machine', count=1),\n",
       " Row(word='building', count=2),\n",
       " Row(word='params', count=1),\n",
       " Row(word='given.', count=1),\n",
       " Row(word='be', count=2),\n",
       " Row(word='same', count=1),\n",
       " Row(word='integration', count=1),\n",
       " Row(word='Programs', count=1),\n",
       " Row(word='locally', count=2),\n",
       " Row(word='using:', count=1),\n",
       " Row(word='[Apache', count=1),\n",
       " Row(word='your', count=1),\n",
       " Row(word='optimized', count=1),\n",
       " Row(word='Developer', count=1),\n",
       " Row(word='R,', count=1),\n",
       " Row(word='[![AppVeyor', count=1),\n",
       " Row(word='should', count=2),\n",
       " Row(word='graph', count=1),\n",
       " Row(word='package', count=1),\n",
       " Row(word='[project', count=1),\n",
       " Row(word='project', count=1),\n",
       " Row(word='`examples`', count=2),\n",
       " Row(word='resource-managers/kubernetes/integration-tests/README.md', count=1),\n",
       " Row(word='versions', count=1),\n",
       " Row(word='Spark\"](https://spark.apache.org/docs/latest/building-spark.html).', count=1),\n",
       " Row(word='Spark](#building-spark).', count=1),\n",
       " Row(word='general', count=2),\n",
       " Row(word='other', count=1),\n",
       " Row(word='1000', count=2),\n",
       " Row(word='learning,', count=1),\n",
       " Row(word='when', count=1),\n",
       " Row(word='submit', count=1),\n",
       " Row(word='Apache', count=1),\n",
       " Row(word='detailed', count=2),\n",
       " Row(word='About', count=1),\n",
       " Row(word='is', count=7),\n",
       " Row(word='on', count=7),\n",
       " Row(word='scala>', count=1),\n",
       " Row(word='print', count=1),\n",
       " Row(word='Tools\"](https://spark.apache.org/developer-tools.html).', count=1),\n",
       " Row(word='use', count=3),\n",
       " Row(word='different', count=1),\n",
       " Row(word='following', count=2),\n",
       " Row(word='YARN\"](https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)', count=1),\n",
       " Row(word='<https://spark.apache.org/>', count=1),\n",
       " Row(word='SparkPi', count=2),\n",
       " Row(word='refer', count=2),\n",
       " Row(word='./bin/run-example', count=2),\n",
       " Row(word='data', count=2),\n",
       " Row(word='Tests', count=1),\n",
       " Row(word='Versions', count=1),\n",
       " Row(word='processing.', count=2),\n",
       " Row(word='its', count=1),\n",
       " Row(word='tests](https://spark.apache.org/developer-tools.html#individual-tests).', count=1),\n",
       " Row(word='basic', count=1),\n",
       " Row(word='latest', count=1),\n",
       " Row(word='only', count=1),\n",
       " Row(word='<class>', count=1),\n",
       " Row(word='have', count=1),\n",
       " Row(word='runs.', count=1),\n",
       " Row(word='You', count=3),\n",
       " Row(word='tips,', count=1),\n",
       " Row(word='project.', count=1),\n",
       " Row(word='developing', count=1),\n",
       " Row(word='YARN,', count=1),\n",
       " Row(word='It', count=2),\n",
       " Row(word='\"local\"', count=1),\n",
       " Row(word='processing,', count=1),\n",
       " Row(word='built', count=1),\n",
       " Row(word='Pi', count=1),\n",
       " Row(word='thread,', count=1),\n",
       " Row(word='A', count=1),\n",
       " Row(word='APIs', count=1),\n",
       " Row(word='Scala,', count=1),\n",
       " Row(word='file', count=1),\n",
       " Row(word='computation', count=1),\n",
       " Row(word='Once', count=1),\n",
       " Row(word='find', count=1),\n",
       " Row(word='the', count=23),\n",
       " Row(word='To', count=2),\n",
       " Row(word='uses', count=1),\n",
       " Row(word='Version', count=1),\n",
       " Row(word='N', count=1),\n",
       " Row(word='programs,', count=1),\n",
       " Row(word='\"yarn\"', count=1),\n",
       " Row(word='see', count=3),\n",
       " Row(word='./bin/pyspark', count=1),\n",
       " Row(word='Structured', count=1),\n",
       " Row(word='[![Jenkins', count=1),\n",
       " Row(word='return', count=2),\n",
       " Row(word='Java,', count=1),\n",
       " Row(word='from', count=1),\n",
       " Row(word='Because', count=1),\n",
       " Row(word='Streaming', count=1),\n",
       " Row(word='More', count=1),\n",
       " Row(word='cluster', count=1),\n",
       " Row(word='analytics', count=1),\n",
       " Row(word='analysis.', count=1),\n",
       " Row(word='cluster.', count=1),\n",
       " Row(word='Running', count=1),\n",
       " Row(word='Please', count=4),\n",
       " Row(word='talk', count=1),\n",
       " Row(word='distributions.', count=1),\n",
       " Row(word='guide,', count=1),\n",
       " Row(word='There', count=1),\n",
       " Row(word='\"local[N]\"', count=1),\n",
       " Row(word='Try', count=1),\n",
       " Row(word='and', count=9),\n",
       " Row(word='do', count=2),\n",
       " Row(word='Scala', count=2),\n",
       " Row(word='class', count=2),\n",
       " Row(word='build', count=3),\n",
       " Row(word='setup', count=1),\n",
       " Row(word='need', count=1),\n",
       " Row(word='spark://', count=1),\n",
       " Row(word='Hadoop,', count=2),\n",
       " Row(word='Thriftserver', count=1),\n",
       " Row(word='are', count=1),\n",
       " Row(word='requires', count=1),\n",
       " Row(word='package.', count=1),\n",
       " Row(word='Enabling', count=1),\n",
       " Row(word='clean', count=1),\n",
       " Row(word='large-scale', count=1),\n",
       " Row(word='high-level', count=1),\n",
       " Row(word='SQL', count=2),\n",
       " Row(word='page](https://spark.apache.org/documentation.html).', count=1),\n",
       " Row(word='against', count=1),\n",
       " Row(word='of', count=5),\n",
       " Row(word='through', count=1),\n",
       " Row(word='review', count=1),\n",
       " Row(word='package.)', count=1),\n",
       " Row(word='Python,', count=2),\n",
       " Row(word='easiest', count=1),\n",
       " Row(word='no', count=1),\n",
       " Row(word='Testing', count=1),\n",
       " Row(word='several', count=1),\n",
       " Row(word='help', count=1),\n",
       " Row(word='The', count=1),\n",
       " Row(word='sample', count=1),\n",
       " Row(word='MASTER=spark://host:7077', count=1),\n",
       " Row(word='examples', count=2),\n",
       " Row(word='an', count=4),\n",
       " Row(word='#', count=1),\n",
       " Row(word='Online', count=1),\n",
       " Row(word='test,', count=1),\n",
       " Row(word='including', count=4),\n",
       " Row(word='usage', count=1),\n",
       " Row(word='Python', count=2),\n",
       " Row(word='at', count=2),\n",
       " Row(word='development', count=1),\n",
       " Row(word='IDE,', count=1),\n",
       " Row(word='way', count=1),\n",
       " Row(word='Contributing', count=1),\n",
       " Row(word='get', count=1),\n",
       " Row(word='that', count=2),\n",
       " Row(word='##', count=9),\n",
       " Row(word='For', count=3),\n",
       " Row(word='prefer', count=1),\n",
       " Row(word='This', count=2),\n",
       " Row(word='running', count=1),\n",
       " Row(word='Build](https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&logo=appveyor)](https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark)', count=1),\n",
       " Row(word='web', count=1),\n",
       " Row(word='run', count=7),\n",
       " Row(word='locally.', count=1),\n",
       " Row(word='Spark', count=14),\n",
       " Row(word='URL,', count=1),\n",
       " Row(word='a', count=9),\n",
       " Row(word='higher-level', count=1),\n",
       " Row(word='tools', count=1),\n",
       " Row(word='if', count=4),\n",
       " Row(word='available', count=1),\n",
       " Row(word='', count=49),\n",
       " Row(word='Documentation', count=1),\n",
       " Row(word='this', count=1),\n",
       " Row(word='Maven](https://maven.apache.org/).', count=1),\n",
       " Row(word='(You', count=1),\n",
       " Row(word='Build](https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7-hive-2.3/badge/icon)](https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7-hive-2.3)', count=1),\n",
       " Row(word='>>>', count=1),\n",
       " Row(word='information', count=1),\n",
       " Row(word='info', count=1),\n",
       " Row(word='unified', count=1),\n",
       " Row(word='Shell', count=2),\n",
       " Row(word='environment', count=1),\n",
       " Row(word='built,', count=1),\n",
       " Row(word='module,', count=1),\n",
       " Row(word='them,', count=1),\n",
       " Row(word='`./bin/run-example', count=1),\n",
       " Row(word='instance:', count=1),\n",
       " Row(word='first', count=1),\n",
       " Row(word='[Contribution', count=1),\n",
       " Row(word='documentation,', count=1),\n",
       " Row(word='[params]`.', count=1),\n",
       " Row(word='mesos://', count=1),\n",
       " Row(word='engine', count=2),\n",
       " Row(word='GraphX', count=1),\n",
       " Row(word='example:', count=1),\n",
       " Row(word='HDFS', count=1),\n",
       " Row(word='or', count=3),\n",
       " Row(word='to', count=16),\n",
       " Row(word='Hadoop', count=3),\n",
       " Row(word='individual', count=1),\n",
       " Row(word='also', count=5),\n",
       " Row(word='changed', count=1),\n",
       " Row(word='started', count=1),\n",
       " Row(word='./bin/spark-shell', count=1),\n",
       " Row(word='threads.', count=1),\n",
       " Row(word='supports', count=2),\n",
       " Row(word='storage', count=1),\n",
       " Row(word='version', count=1),\n",
       " Row(word='instructions.', count=1),\n",
       " Row(word='Building', count=1),\n",
       " Row(word='start', count=1),\n",
       " Row(word='Many', count=1),\n",
       " Row(word='which', count=2),\n",
       " Row(word='Coverage](https://img.shields.io/badge/dynamic/xml.svg?label=pyspark%20coverage&url=https%3A%2F%2Fspark-test.github.io%2Fpyspark-coverage-site&query=%2Fhtml%2Fbody%2Fdiv%5B1%5D%2Fdiv%2Fh1%2Fspan&colorB=brightgreen&style=plastic)](https://spark-test.github.io/pyspark-coverage-site)', count=1),\n",
       " Row(word='spark.range(1000', count=2),\n",
       " Row(word='And', count=1),\n",
       " Row(word='distribution', count=1)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collect\n",
    "wordCounts = textFile.select(explode(split(textFile.value, \"\\s+\")).alias(\"word\")).groupBy(\"word\").count()\n",
    "wordCounts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e883489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建dataframe\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0d435aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "|    10|\n",
      "|    11|\n",
      "|    12|\n",
      "|    13|\n",
      "|    14|\n",
      "|    15|\n",
      "|    16|\n",
      "|    17|\n",
      "|    18|\n",
      "|    19|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(1000).toDF(\"number\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac2c9fde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23380/3963935657.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"A\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m112233\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m223311\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m331122\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mschema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStructType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStructField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStructField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"age\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStructField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"phone\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakeRDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Seq' is not defined"
     ]
    }
   ],
   "source": [
    "data = Seq(Row(\"A\", 10, 112233),Row(\"B\", 20, 223311),Row(\"C\", 30, 331122))\n",
    "schema = StructType(List(StructField(\"name\", StringType),StructField(\"age\", IntegerType),StructField(\"phone\", IntegerType)))\n",
    "spark.createDataFrame(sc.makeRDD(data), schema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe创建与常规操作（scala下）\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import spark.implicits._\n",
    "spark=SparkSession.builder().getOrCreate()\n",
    "df = spark.read.json(\"file:///C:/Users/72952/Desktop/scala/people.json\")\n",
    "scala> df.show()\n",
    "+----+-------+\n",
    "| age|   name|\n",
    "+----+-------+\n",
    "|null|Michael|\n",
    "|  30|   Andy|\n",
    "|  19| Justin|\n",
    "+----+-------+\n",
    "# 打印模式信息\n",
    "scala> df.printSchema()\n",
    "root\n",
    " |-- age: long (nullable = true)\n",
    " |-- name: string (nullable = true)\n",
    "\n",
    "#选择多列\n",
    "scala> df.select(df(\"name\"),df(\"age\")+1).show()\n",
    "+-------+---------+\n",
    "|   name|(age + 1)|\n",
    "+-------+---------+\n",
    "|Michael|     null|\n",
    "|   Andy|       31|\n",
    "| Justin|       20|\n",
    "+-------+---------+\n",
    "\n",
    "# 条件过滤\n",
    "scala> df.filter(df(\"age\") > 20 ).show()\n",
    "+---+----+\n",
    "|age|name|\n",
    "+---+----+\n",
    "| 30|Andy|\n",
    "+---+----+\n",
    "\n",
    "# 分组聚合\n",
    "scala> df.groupBy(\"age\").count().show()\n",
    "+----+-----+\n",
    "| age|count|\n",
    "+----+-----+\n",
    "|  19|    1|\n",
    "|null|    1|\n",
    "|  30|    1|\n",
    "+----+-----+\n",
    "\n",
    "# 排序\n",
    "scala> df.sort(df(\"age\").desc).show()\n",
    "+----+-------+\n",
    "| age|   name|\n",
    "+----+-------+\n",
    "|  30|   Andy|\n",
    "|  19| Justin|\n",
    "|null|Michael|\n",
    "+----+-------+\n",
    "\n",
    "#多列排序\n",
    "scala> df.sort(df(\"age\").desc, df(\"name\").asc).show()\n",
    "+----+-------+\n",
    "| age|   name|\n",
    "+----+-------+\n",
    "|  30|   Andy|\n",
    "|  19| Justin|\n",
    "|null|Michael|\n",
    "+----+-------+\n",
    "\n",
    "#对列进行重命名\n",
    "scala> df.select(df(\"name\").as(\"username\"),df(\"age\")).show()\n",
    "+--------+----+\n",
    "|username| age|\n",
    "+--------+----+\n",
    "| Michael|null|\n",
    "|    Andy|  30|\n",
    "|  Justin|  19|\n",
    "+--------+----+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235e3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
